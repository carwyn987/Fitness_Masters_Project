{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Resources:\n",
    "\n",
    "https://github.com/opencv/opencv/issues/18120\n",
    "https://stackoverflow.com/questions/9868963/cvimwrite-could-not-find-a-writer-for-the-specified-extension\n",
    "https://pyimagesearch.com/2020/07/27/opencv-grabcut-foreground-segmentation-and-extraction/\n",
    "https://www.geeksforgeeks.org/python-opencv-cv2-imwrite-method/\n",
    "\n",
    "This file contains test code that runs the GrabCut algorithm on a sample image. Later it will include testing for robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-i IMAGE] [-c ITER]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/carwyn/.local/share/jupyter/runtime/kernel-4b31f259-12b7-4105-8461-ec0d7b943aee.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carwyn/anaconda3/envs/hypertrophy/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3465: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--image\", type=str,\n",
    "\tdefault=os.path.sep.join([\"images\", \"adrian.jpg\"]),\n",
    "\thelp=\"path to input image that we'll apply GrabCut to\")\n",
    "ap.add_argument(\"-i\", \"--save-to\", type=str,\n",
    "\tdefault=\"../../Media/Computed_Media/image_segmentation/\",\n",
    "\thelp=\"path to saved output images\")\n",
    "ap.add_argument(\"-c\", \"--iter\", type=int, default=10,\n",
    "\thelp=\"# of GrabCut iterations (larger value => slower runtime)\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ipynb, simulate inputs\n",
    "image = \"../../Media/Images/original_leg_day/FLIR_20220906_102026_232-Visual.jpeg\"\n",
    "computed_media_folder = \"../../Media/Computed_Media/image_segmentation/\"\n",
    "iter = 10\n",
    "\n",
    "args = {\"image\":image, \"iter\":iter}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(args[\"image\"])\n",
    "mask = np.zeros(image.shape[:2], dtype=\"uint8\")\n",
    "\n",
    "# Print image with axes to estimate bounding box\n",
    " \n",
    "cv2.imshow(\"Sample Image\", image)\n",
    "cv2.waitKey(0) # Wait for a keypress otherwise the kernel instantly crashes\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "rect = (246, 200, 700, 1330)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] applying GrabCut took 5.05 seconds\n"
     ]
    }
   ],
   "source": [
    "# allocate memory for two arrays that the GrabCut algorithm internally\n",
    "# uses when segmenting the foreground from the background\n",
    "fgModel = np.zeros((1, 65), dtype=\"float\")\n",
    "bgModel = np.zeros((1, 65), dtype=\"float\")\n",
    "\n",
    "# apply GrabCut using the the bounding box segmentation method\n",
    "start = time.time()\n",
    "(mask, bgModel, fgModel) = cv2.grabCut(image, mask, rect, bgModel,\n",
    "\tfgModel, iterCount=args[\"iter\"], mode=cv2.GC_INIT_WITH_RECT)\n",
    "end = time.time()\n",
    "print(\"[INFO] applying GrabCut took {:.2f} seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] showing mask for 'Definite Background'\n",
      "[INFO] showing mask for 'Probable Background'\n",
      "[INFO] showing mask for 'Definite Foreground'\n",
      "[INFO] showing mask for 'Probable Foreground'\n"
     ]
    }
   ],
   "source": [
    "# the output mask has for possible output values, marking each pixel\n",
    "# in the mask as (1) definite background, (2) definite foreground,\n",
    "# (3) probable background, and (4) probable foreground\n",
    "values = (\n",
    "\t(\"Definite Background\", cv2.GC_BGD),\n",
    "\t(\"Probable Background\", cv2.GC_PR_BGD),\n",
    "\t(\"Definite Foreground\", cv2.GC_FGD),\n",
    "\t(\"Probable Foreground\", cv2.GC_PR_FGD),\n",
    ")\n",
    "# loop over the possible GrabCut mask values\n",
    "for (name, value) in values:\n",
    "    # construct a mask that for the current value\n",
    "    print(\"[INFO] showing mask for '{}'\".format(name))\n",
    "    valueMask = (mask == value).astype(\"uint8\") * 255\n",
    "    # display the mask so we can visualize it\n",
    "    cv2.imshow(name, valueMask)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll set all definite background and probable background pixels\n",
    "# to 0 while definite foreground and probable foreground pixels are\n",
    "# set to 1\n",
    "outputMask = np.where((mask == cv2.GC_BGD) | (mask == cv2.GC_PR_BGD),\n",
    "\t0, 1)\n",
    "# scale the mask from the range [0, 1] to [0, 255]\n",
    "outputMask = (outputMask * 255).astype(\"uint8\")\n",
    "# apply a bitwise AND to the image using our mask generated by\n",
    "# GrabCut to generate our final output image\n",
    "output = cv2.bitwise_and(image, image, mask=outputMask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Input\", image)\n",
    "cv2.imshow(\"GrabCut Mask\", outputMask)\n",
    "cv2.imshow(\"GrabCut Output\", output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write Files to Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the images to Computed Media folder\n",
    "cv2.imwrite(computed_media_folder + \"input_image.png\", image)\n",
    "cv2.imwrite(computed_media_folder + \"output_mask.png\", outputMask)\n",
    "cv2.imwrite(computed_media_folder + \"output_image.png\", output)\n",
    "\n",
    "for (name, value) in values:\n",
    "    valueMask = (mask == value).astype(\"uint8\") * 255\n",
    "    cv2.imwrite(computed_media_folder + name.replace(\" \", '-') + \".png\", valueMask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that a proof of concept segmenter is in place, the next steps are as follows:\n",
    "\n",
    "We must test the robustness of the GrabCut algorithm\n",
    " - Since this implementation of GrabCut uses an estimated bounding box of the object, this must be evaluated from the standpoint of an application for consumers. Is it realistic that a client would highlight the leg/arm/appendige in every image they want analyzed? And how accurate should it be for GrabCut to work consistently well.\n",
    " - If it is not robust, RINDNet or some other segmenter must be put in place to either improve or replace solely GrabCut.\n",
    " - The final algorithm is constrained to be something that can run on a cell phone processor or API calls from phone (low network usage)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypertrophy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16 (default, Jan 17 2023, 22:20:44) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fab640fafe63b1fa1ad89386334ad1f3bfbfe350729bb4fe9539462594b39904"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
