{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Segmentation Model with Lab Dataset\n",
    "\n",
    "Based off of:\n",
    "\n",
    "https://towardsdatascience.com/train-neural-net-for-semantic-segmentation-with-pytorch-in-50-lines-of-code-830c71a6544f\n",
    "https://github.com/sagieppel/Train-Semantic-Segmentation-Net-with-Pytorch-In-50-Lines-Of-Code \n",
    "\n",
    "MIT License - use available for commercial use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torchvision.models.segmentation\n",
    "import torch\n",
    "import torchvision.transforms as tf\n",
    "import random\n",
    "\n",
    "Learning_Rate=1e-5\n",
    "width=height=800 # image width and height\n",
    "batchSize=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainFolder=\"Data/LabPicsV1/Simple/Train/\"\n",
    "ListImages=os.listdir(os.path.join(TrainFolder, \"Image\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformImg=tf.Compose([tf.ToPILImage(),tf.Resize((height,width)), tf.ToTensor(),tf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "transformAnn=tf.Compose([tf.ToPILImage(),tf.Resize((height,width)), tf.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in custom directory:  69\n"
     ]
    }
   ],
   "source": [
    "probability = 1\n",
    "second_train_folder = \"../../Skin_Anatomical_Image_Dataset/simple_image_config\"\n",
    "\n",
    "cust_img_path = os.path.join(second_train_folder, \"images\")\n",
    "cust_mask_path = os.path.join(second_train_folder, \"masks\")\n",
    "\n",
    "custom_imgs = os.listdir(cust_img_path)\n",
    "custom_masks = os.listdir(cust_mask_path)\n",
    "\n",
    "# Get length of directory\n",
    "len_custom_masks = len(custom_masks)\n",
    "print(\"Number of files in custom directory: \", len_custom_masks)\n",
    "\n",
    "def ReadRandomImage(show=False):\n",
    "\n",
    "    # Probabilistically read in an image that is from our custom dataset\n",
    "    if random.random() < probability:\n",
    "        idx=np.random.randint(0,len_custom_masks)\n",
    "\n",
    "        # print(\"Idx: \", idx, \" filename: \", custom_imgs[idx], \", \", custom_masks[idx])\n",
    "        \n",
    "        Img=cv2.imread(os.path.join(cust_img_path,custom_imgs[idx]))\n",
    "        Vessel =  cv2.imread(os.path.join(cust_mask_path, custom_masks[idx])).max(axis=2) # perhaps switch custom_masks[idx] with custom_imgs[idx] to match image\n",
    "        Vessel[Vessel == None] = 1\n",
    "        Vessel.astype(int)\n",
    "        AnnMap = np.zeros(Img.shape[0:2],np.float32)\n",
    "        Filled = None\n",
    "        # print(\"Vessel Shape: \", Vessel.shape)\n",
    "    else:\n",
    "        idx=np.random.randint(0,len(ListImages)) # Pick random image   \n",
    "        Img=cv2.imread(os.path.join(TrainFolder, \"Image\",ListImages[idx]))  \n",
    "        Filled =  cv2.imread(os.path.join(TrainFolder,   \"Semantic/16_Filled\", ListImages[idx].replace(\"jpg\",\"png\")),0)       \n",
    "    \n",
    "        Vessel =  cv2.imread(os.path.join(TrainFolder, \"Semantic/1_Vessel\", ListImages[idx].replace(\"jpg\",\"png\")),0)\n",
    "        # print(\"Vessel Shape2: \", Vessel.shape)\n",
    "        AnnMap = np.zeros(Img.shape[0:2],np.float32) # Segmentation map\n",
    "\n",
    "    if show:\n",
    "        print(\"Image path: \", str(os.path.join(TrainFolder, \"Image\",ListImages[idx])))\n",
    "        # show the image, provide window name first\n",
    "        cv2.imshow('Img', Img)\n",
    "        cv2.waitKey(0)\n",
    "        # cv2.imshow('Filled', Filled)\n",
    "        # cv2.waitKey(0)\n",
    "        cv2.imshow('Vessel', Vessel)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        # print(\"Filled: \", Filled)\n",
    "        print(\"Vessel num: \", np.count_nonzero(Vessel), \"/\", Vessel.shape, \", range of values: [\", np.min(Vessel), \", \", np.max(Filled), \"]\")\n",
    "        print(\"Vessel: \", Vessel)\n",
    "        print(\"AnnMap: \", AnnMap)\n",
    "    \n",
    "    if Vessel is not None:  \n",
    "        AnnMap[ Vessel == 1 ] = 1    \n",
    "    if Filled is not None:  \n",
    "        AnnMap[ Filled  == 1 ] = 2\n",
    "\n",
    "    Img=transformImg(Img)\n",
    "    AnnMap=transformAnn(AnnMap)\n",
    "\n",
    "    return Img,AnnMap, Vessel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image path:  Data/LabPicsV1/Simple/Train/Image/IMG_20190302_220740.jpg\n",
      "Filled num:  4186416 / (3024, 4032) , range of values: [ 0 ,  None ]\n",
      "Vessel:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "AnnMap:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Print test images form dataset\n",
    "Img,AnnMap, Vessel = ReadRandomImage(show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------Load batch of images-----------------------------------------------------\n",
    "def LoadBatch(): # Load batch of images\n",
    "    images = torch.zeros([batchSize,3,height,width])\n",
    "    ann = torch.zeros([batchSize, height, width])\n",
    "\n",
    "    for i in range(batchSize):\n",
    "        images[i],ann[i],_=ReadRandomImage()\n",
    "    \n",
    "    return images, ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carwyn/anaconda3/envs/hypertrophy/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/home/carwyn/anaconda3/envs/hypertrophy/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#--------------Load and set net and optimizer-------------------------------------\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "Net = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=True) # Load net\n",
    "Net.classifier[4] = torch.nn.Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1)) # Change final layer to 3 classes\n",
    "Net=Net.to(device)\n",
    "optimizer=torch.optim.Adam(params=Net.parameters(),lr=Learning_Rate) # Create adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ) Loss= 1.1937019\n",
      "Saving Model0.torch\n",
      "1 ) Loss= 1.1891718\n",
      "2 ) Loss= 1.1922604\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_71772/3272893723.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#----------------Train--------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m    \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mann\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLoadBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Load taining batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m    \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Load image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m    \u001b[0mann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Load annotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_71772/2081452279.py\u001b[0m in \u001b[0;36mLoadBatch\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mann\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mReadRandomImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mann\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_71772/4148468743.py\u001b[0m in \u001b[0;36mReadRandomImage\u001b[0;34m(show)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# print(\"Idx: \", idx, \" filename: \", custom_imgs[idx], \", \", custom_masks[idx])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mImg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcust_img_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcustom_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mVessel\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcust_mask_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_masks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# perhaps switch custom_masks[idx] with custom_imgs[idx] to match image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mAnnMap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#----------------Train--------------------------------------------------------------------------\n",
    "for itr in range(2001): # Training loop\n",
    "   images,ann=LoadBatch() # Load taining batch\n",
    "   images=torch.autograd.Variable(images,requires_grad=False).to(device) # Load image\n",
    "   ann = torch.autograd.Variable(ann, requires_grad=False).to(device) # Load annotation\n",
    "   Pred=Net(images)['out'] # make prediction\n",
    "   Net.zero_grad()\n",
    "   criterion = torch.nn.CrossEntropyLoss() # Set loss function\n",
    "   Loss=criterion(Pred,ann.long()) # Calculate cross entropy loss\n",
    "   Loss.backward() # Backpropogate loss\n",
    "   optimizer.step() # Apply gradient descent change to weight\n",
    "   seg = torch.argmax(Pred[0], 0).cpu().detach().numpy()  # Get  prediction classes\n",
    "   print(itr,\") Loss=\",Loss.data.cpu().numpy())\n",
    "   \n",
    "   if itr % 1000 == 0: #Save model weight once every 60k steps permenant file\n",
    "        print(\"Saving Model\" +str(itr) + \".torch\")\n",
    "        torch.save(Net.state_dict(),  \"custom_dataset_p_1_\" + str(itr) + \".torch\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypertrophy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fab640fafe63b1fa1ad89386334ad1f3bfbfe350729bb4fe9539462594b39904"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
